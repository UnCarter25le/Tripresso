{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tripresso\n",
    "------\n",
    "## Intention of this project:\n",
    "\n",
    "- In order to meet __Tripresso Corporation's ([website](https://www.tripresso.com/ \"旅遊咖\"))__ expectation.\n",
    "\n",
    "Making a crawler for these website\n",
    "    - https://www.newamazing.com.tw/EW/GO/GroupList.asp   \n",
    "\n",
    "    - http://www.orangetour.com.tw/EW/GO/GroupList.asp\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "# Next, there are several parts having those who are interested in here get evolved in this project  easily.\n",
    "> ##  FIRST-------------packageNeeded:\n",
    "\n",
    "- ## Package needed for database:\n",
    "![database](https://github.com/UnCarter25le/Tripresso/blob/master/packageNeededForDatabase.png)\n",
    "\n",
    "\n",
    "- ## Package needed for crawler:\n",
    "![crawler](https://github.com/UnCarter25le/Tripresso/blob/master/packageNeededForCrawler.png)\n",
    "\n",
    "- ## Python 3.6.6 and MySQL 5.7.25\n",
    "\n",
    "> ##  SECOND-------------Project Overview: \n",
    "\n",
    "![ProjectOverview](https://github.com/UnCarter25le/Tripresso/blob/master/ProjectOverview.png)\n",
    "\n",
    "- ## DatabaseInfo: \n",
    "This is the place showing us information about database(MySQL), such as each table condition, ERmodel for Tripresso [website](https://www.tripresso.com/agency/NEWAMAZE \"旅遊咖x新魅力\"),the overview for database named __\"tripresso\"__,and back-up file named __\"back_tripresso.sql\"__ for corresponding database.\n",
    "\n",
    "- ## DataSetAndPrograms:\n",
    "    - this is the place showing us details concerning executable programs and usable dataset. For example, it would take us about __1200 seconds__ to executing __\"crawlerForNewAmazing.py\"__ and __\"crawlerForOrangeTour.py\"__, which will generate raw data in html-txt format and download photos for follow-up data processing. It will be help to __reduce precious time__ by leaving comments at lines __\"photoUri and photoDownload...\"__:\n",
    "\n",
    "```\n",
    "若不要下載圖片，請在下面一組if else中註解掉photoUri and photoDownload。 圖片有部屬在不同的網域中。。。\n",
    "if \"http://dcimg.travel.net.tw\" in imgUrn:\n",
    "    dataDictInner['domainUrl'] = domainUrl\n",
    "    dataDictInner['imgUrn'] = imgUrn            \n",
    "    photoUri = imgUrn\n",
    "    photoDownload(photoUri,photoFolder,plan_id,tripPlanCodeName)\n",
    "else:\n",
    "    dataDictInner['domainUrl'] = domainUrl\n",
    "    dataDictInner['imgUrn'] = imgUrn                \n",
    "    photoUri = domainUrl + imgUrn\n",
    "    photoDownload(photoUri,photoFolder,plan_id,tripPlanCodeName)    \n",
    "```\n",
    "\n",
    "   - Also, I have default pages from 1 to 10, and we are able to adjust it to the effective range!\n",
    "```\n",
    "for page in range(1,11):\n",
    "    crawler(page,url)\n",
    "```\n",
    "\n",
    "   - Next, we are capable of downloading photos alternatively by executing __\"photoForNewAmazing.py\"__ and __\"photoForOrangeTour.py\"__ to have those if we have done jobs of getting raw data(checking the folder named __crawlerForNewamazing__ and __crawlerForOrangetour__.) __Look, if completing photos download at the initial stage, we can neglect this part!__\n",
    "    - Fourthly, after removing possible duplicates in data set, we have to rely on files to give us a favor to insert data into database, such as __\"newAmazing_199_SET.json\"__,__\"DateOf2019.json\"__,__\"orangetour_200.json\"__,__\"photoForNewamazing_SET\"__,__\"photoForOrangetour\"__. I believe it's time to checking us MySQL account information!\n",
    "![MySQL account](https://github.com/UnCarter25le/Tripresso/blob/master/pleaseCheckAccountInfoForMySQL.png)\n",
    "\n",
    "   - Finally, before executing two files,__\"createTables.py\"__ and __\"dataInsert.py\"__ to have data into database, please create  a database named __\"tripresso\"__ and it's format must be compatiable utf8mb4! If we get ready for executing two files, we can just do it now.\n",
    "    \n",
    "   - __NOTE: we can directly use back-up file named  \"back_tripresso.sql\" to import data immediately. Of course, creating database named \"tripresso\" is necessary.__ \n",
    "\n",
    "- ## PhotoSet:\n",
    "\n",
    "    - Here is notes for making crawlers.\n",
    "- ## iPYNB_File:\n",
    "\n",
    "    - Here is my work places.\n",
    "    \n",
    "    \n",
    ">  ## THIRD-------------Database Info: \n",
    "\n",
    "- ## I believe these photos will help us to take a closer look at how is going on in executing programs:\n",
    "\n",
    "    - ERmodel for Tripresso [website](https://www.tripresso.com/agency/NEWAMAZE \"旅遊咖x新魅力\")\n",
    "![ERmodel for Tripresso website](https://github.com/UnCarter25le/Tripresso/blob/master/DatabaseInfo/TripressoERmodel.png)\n",
    "\n",
    "    - Database overview:\n",
    "![database overview](https://github.com/UnCarter25le/Tripresso/blob/master/DatabaseInfo/databaseOverview.png)\n",
    "\n",
    "    - table_Continent:\n",
    "![--](https://github.com/UnCarter25le/Tripresso/blob/master/DatabaseInfo/table_Continent.png)\n",
    "    \n",
    "    - table_Country:\n",
    "![--](https://github.com/UnCarter25le/Tripresso/blob/master/DatabaseInfo/table_Country.png)\n",
    "    \n",
    "    - table_Date:\n",
    "![--](https://github.com/UnCarter25le/Tripresso/blob/master/DatabaseInfo/table_Date.png)\n",
    "\n",
    "    - table_Date_And_TripPlan:\n",
    "![--](https://github.com/UnCarter25le/Tripresso/blob/master/DatabaseInfo/table_Date_And_TripPlan.png)\n",
    "\n",
    "    - table_Evaluation_Of_PartnerCorp:\n",
    "![--](https://github.com/UnCarter25le/Tripresso/blob/master/DatabaseInfo/table_Evaluation_Of_PartnerCorp.png)\n",
    "\n",
    "    - table_Giveaway:\n",
    "![--](https://github.com/UnCarter25le/Tripresso/blob/master/DatabaseInfo/table_Giveaway.png)\n",
    "\n",
    "    - table_PartnerCorp:\n",
    "![--](https://github.com/UnCarter25le/Tripresso/blob/master/DatabaseInfo/table_PartnerCorp.png)\n",
    "\n",
    "    - table_TripPlan:\n",
    "![--](https://github.com/UnCarter25le/Tripresso/blob/master/DatabaseInfo/table_TripPlan.png)\n",
    "\n",
    "    - table_WowFactor:\n",
    "![--](https://github.com/UnCarter25le/Tripresso/blob/master/DatabaseInfo/table_WowFactor.png)\n",
    "\n",
    "    - table_WowFactor_And_TripPlan:\n",
    "![--](https://github.com/UnCarter25le/Tripresso/blob/master/DatabaseInfo/table_WowFactor_And_TripPlan.png)\n",
    "\n",
    " \n",
    "-----\n",
    "\n",
    "\n",
    "# Finally, for me:)\n",
    "\n",
    "\n",
    "it's not until completing this mission that I have this chance to sharpen my skills further more as to web scraping, functional programming style, and entity relationship modeling. I wish those who are watching this project now will be moved by __my industrious attitude.__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
