{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "import pytz\n",
    "import requests,json,os,time,random,re\n",
    "from bs4 import BeautifulSoup\n",
    "import base64\n",
    "\n",
    "def getTime():\n",
    "    \"\"\"\n",
    "    show the present time.\n",
    "    \"\"\"\n",
    "    CN = pytz.timezone('Asia/Taipei')\n",
    "    CN.zone\n",
    "    CN_time =CN.localize(datetime.now())#+ timedelta(hours=8))\n",
    "    fmt = \"%Y年_%m月_%d日_%H時_%M分\"\n",
    "    now = CN_time.strftime(fmt)\n",
    "    return now\n",
    "\n",
    "def searchNums(url):\n",
    "    \"\"\"\n",
    "    :type:url:string\n",
    "    :rtype:number:string\n",
    "    regular expression in one url string to find out number.\n",
    "    \"\"\"\n",
    "    searchNum = re.compile('\\d+')\n",
    "    number = searchNum.search(url).group()\n",
    "    return number\n",
    "\n",
    "def str2dict(data_str):\n",
    "    \"\"\"\n",
    "    :type:data_str:string\n",
    "    :rtype:data:Dict\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for row in data_str.split(\"\\n\"):\n",
    "        kv_list = row.split(\":\")\n",
    "        data[kv_list[0]] = kv_list[1].replace(' ','').replace('/','-')\n",
    "    return data\n",
    "\n",
    "def timeSleepRandom():\n",
    "    \"\"\"\n",
    "    sleep randomly between 1s and 2s.\n",
    "    \"\"\"\n",
    "    time.sleep(random.randrange(1,3))\n",
    "\n",
    "def timeSleep():\n",
    "    \"\"\"\n",
    "    sleep 4s\n",
    "    \"\"\"\n",
    "    time.sleep(4)\n",
    "\n",
    "def mkdir(folderName):\n",
    "    \"\"\"\n",
    "    :type:folderName:string\n",
    "    create a folder in present working directroy.\n",
    "    \"\"\"\n",
    "    folder = \"./{}/\".format(folderName)\n",
    "    if os.path.exists(folder):\n",
    "        print('已經存在 '+folderName)\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(folder)\n",
    "        print('創建 '+folderName+\"！\")   \n",
    "\n",
    "def crawler(page,url):\n",
    "    \"\"\"\n",
    "    :type:page:int\n",
    "    :type:url:string\n",
    "    web scraping from https://www.newamazing.com.tw/EW/GO/GroupList.asp \n",
    "    and having responses(txt format) into files in folder created by function mkdir.\n",
    "    \"\"\"\n",
    "    global folderName\n",
    "    global headers\n",
    "    #不要將字串縮排＠＠\n",
    "    form_data = \"\"\"displayType: G\n",
    "subCd: \n",
    "orderCd: 1\n",
    "pageALL: {0}\n",
    "pageGO: 1\n",
    "pagePGO: 1\n",
    "waitData: false\n",
    "waitPage: false\n",
    "mGrupCd: \n",
    "SrcCls: \n",
    "tabList:  \"\"\".format(page)\n",
    "\n",
    "    reSession = requests.Session()\n",
    "\n",
    "    res = reSession.post(url,data = str2dict(form_data),headers = headers)\n",
    "    timeSleepRandom()\n",
    "    soup = BeautifulSoup(res.text,'html.parser')\n",
    "    \n",
    "    with open('./{0}/{1}_{2}_html.txt'.format(folderName,page,'10'),'w',encoding='utf-8')as f:\n",
    "        f.write(str(soup))\n",
    "    print('成功寫出第 '+ str(page) + '頁。')\n",
    "    timeSleep()\n",
    "\n",
    "\n",
    "def initialFile(folderName):\n",
    "    \"\"\"\n",
    "    :type:folderName:string\n",
    "    :rtype:htmltxts:List[string]\n",
    "    listing files orderly via file's name in the specific folder.\n",
    "    \"\"\"\n",
    "    htmltxts = os.listdir('./{}/'.format(folderName))\n",
    "    htmltxts.sort(key=lambda x: int(x.split('_')[0])) #列舉檔案排序\n",
    "    htmltxts.sort(key=lambda x: int(x.split('_')[1])) \n",
    "    return htmltxts\n",
    "\n",
    "def photoDownload(photoUri,photoFolder,plan_id,tripPlanCodeName):\n",
    "    \"\"\"\n",
    "    :type:photoUri:string\n",
    "    :type:photoFolder:string\n",
    "    :type:plan_id:int\n",
    "    :type:tripPlanCodeName:string\n",
    "    downloading photos from photoUri into the specific folder.\n",
    "    \"\"\"\n",
    "    global headers\n",
    "    resImg = requests.get(photoUri,headers = headers)\n",
    "    timeSleepRandom()\n",
    "    deputyFileName = photoUri.split('/')[-1].split('.')[1]\n",
    "    with open('./{0}/{1}_{2}.{3}'.format(photoFolder,plan_id,tripPlanCodeName,deputyFileName),'wb')as f:\n",
    "        f.write(resImg.content)\n",
    "    timeSleep()\n",
    "    print('順利寫出第 '+ str(plan_id)+ '張。')\n",
    "#     encoded_string = base64.b64encode(resImg.content)\n",
    "#     return str(encoded_string,encoding='utf=8')\n",
    "\n",
    "def dataProcessing(folderName,photoFolder,domainUrl):\n",
    "    \"\"\"\n",
    "    :type:folderName:string\n",
    "    :type:photoFolder:string\n",
    "    :type:domainUrl:string\n",
    "    data processing from the files(txt format) in \"folderName\" in order to generate json files we want.\n",
    "    downloading photos from photoUri into the specific folder is alternative!\n",
    "    \"\"\"\n",
    "    global htmltxts\n",
    "    global headers\n",
    "    plan_id = 1\n",
    "    dataDict = {}\n",
    "    for realtxt in htmltxts:\n",
    "        with open('./{0}/{1}'.format(folderName,realtxt),encoding='utf-8')as f:\n",
    "            inn = f.read()\n",
    "        textSoup = BeautifulSoup(inn,'html.parser')\n",
    "        textSoupGetItems = textSoup.select_one('#listDataAll').select('.thumbnail')\n",
    "        for tripPlan in textSoupGetItems:\n",
    "            print('開始處理第 '+str(plan_id)+'筆。')\n",
    "            dataDictInner = {}\n",
    "\n",
    "            dataDictInner['partner_id'] = \"1\" #新魅力\n",
    "            dataDictInner['giveaway_id'] = \"1\" #假設都用第一組贈品資訊\n",
    "            dataDictInner['continent_id'] = \"1\" #假設都指向第一個洲\n",
    "            tripPlanCodeName = tripPlan.select_one('.product_name').text.split('\\n')[1].strip()\n",
    "            dataDictInner['tripPlanCodeName'] = tripPlanCodeName\n",
    "            dataDictInner['tripPlan'] = tripPlan.select_one('.product_name').text.split('\\n')[2].replace('\\r\\n','').strip()\n",
    "            dataDictInner['days'] = searchNums(tripPlan.select_one('.product_days').text)\n",
    "            dataDictInner['dateOfDeparture'] = tripPlan.select_one('.product_date').text.replace('/','-')\n",
    "            dataDictInner['totalNumber'] = searchNums(tripPlan.select_one('.product_total').text)\n",
    "            dataDictInner['availableNumber'] = searchNums(tripPlan.select_one('.product_available').text)\n",
    "            \n",
    "            dataDictInner['expense'] = searchNums(tripPlan.select_one('.product_price').text.split(',')[0])+\\\n",
    "            searchNums(tripPlan.select_one('.product_price').text.split(',')[1])\n",
    "            \n",
    "            imgUrn = tripPlan.select_one('a img').attrs.get('src')\n",
    "#             若不要下載圖片，請在下面一組if else中註解掉photoUri and photoDownload。 圖片有部屬在不同的網域中。。。\n",
    "            if \"http://dcimg.travel.net.tw\" in imgUrn:\n",
    "                dataDictInner['domainUrl'] = domainUrl\n",
    "                dataDictInner['imgUrn'] = imgUrn            \n",
    "                photoUri = imgUrn\n",
    "                photoDownload(photoUri,photoFolder,plan_id,tripPlanCodeName)\n",
    "            else:\n",
    "                dataDictInner['domainUrl'] = domainUrl\n",
    "                dataDictInner['imgUrn'] = imgUrn                \n",
    "                photoUri = domainUrl + imgUrn\n",
    "                photoDownload(photoUri,photoFolder,plan_id,tripPlanCodeName)       \n",
    "          \n",
    "            dataDictInner['tripUrn'] = tripPlan.select_one('a').attrs.get('href')\n",
    "            \n",
    "            dataDict[str(plan_id)] = dataDictInner\n",
    "            print('done '+str(plan_id)+'!')\n",
    "            plan_id += 1\n",
    "    with open('./newAmazing_{0}.json'.format(plan_id-1),'w',encoding='utf-8')as f:\n",
    "        json.dump(dataDict,f,indent=2,ensure_ascii=False)\n",
    "    with open('./newAmazing_{0}_noindent.json'.format(plan_id-1),'w',encoding='utf-8')as f:\n",
    "        json.dump(dataDict,f,ensure_ascii=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    print('現在開始爬蟲，時間是 '+getTime())\n",
    "    \n",
    "    begin = time.time()\n",
    "    \n",
    "    folderName = \"crawlerForNewamazing\"\n",
    "    photoFolder = \"photoForNewamazing\"\n",
    "    url = 'https://www.newamazing.com.tw/EW/GO/GroupList.asp'\n",
    "    domainUrl = 'https://www.newamazing.com.tw'\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko)\"\n",
    "           \"Chrome/72.0.3626.121 Safari/537.36\",\n",
    "          \"Accept-Language\":\"en-US,en;q=0.9\"}\n",
    "    mkdir(folderName)\n",
    "    \n",
    "    for page in range(1,11):\n",
    "        crawler(page,url)\n",
    "        \n",
    "    end = time.time()\n",
    "    \n",
    "    print(\"爬蟲執行完畢，共耗時 \" +str(end-begin)+'秒。')\n",
    "    print('現在開始清洗並下載圖片，時間是 '+getTime())\n",
    "    begin = time.time()\n",
    "    \n",
    "    mkdir(photoFolder)\n",
    "    htmltxts = initialFile(folderName)\n",
    "    dataProcessing(folderName,photoFolder,domainUrl)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"清洗並下載圖片執行完畢，共耗時 \" +str(end-begin)+'秒。')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
